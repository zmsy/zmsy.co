title: Automated Fantasy Baseball Strategy using Web Scraping, Pandas, and Bokeh
---
slug_title: fantasy_baseball
---
author: Zach Morrissey
---
body:

## Winning Fantasy Baseball in Style

Every year I've missed the title in fantasy baseball. This year, I'm attempting to automate my mid-season scouting process to give me a leg up. Every year our group normally comes up with some very good scouting information, but I've got a hunch that I can beat them all out by automating it.

#### The Issues With Pre-Season Scouting

The advantages of scouting out fantasy baseball players in our league evaporates about 3 rounds into the draft. Our group traditionally over-indexes on the drafting portion of it, and then adapts a flying-by-the-seat-of-your-pants approach to the rest of the season. I tend to make bad add/drop decisions as the season goes along. The goal of this project is to fix this particular shortcoming by providing myself with a methodology for doing this throughout the year.

## Getting Data

The data for this exercise comes from a number of places. For a good system, we'll need to retrieve roster data to know who is available, projections to see who is slated to do well, and mid-season player statistics to so who's currently doing well.

### ESPN Roster Data

Our team uses ESPN for our league, which happens to allow access to webpages so long as you take the time to [make the league public](http://games.espn.com/flb/resources/help/content?name=create-league-standard). Getting roster data is fairly straightforward; all you need to do is scrape the rosters page for that league ID. This is an example of that:

```python
import requests
import csv
from bs4 import BeautifulSoup

# rip your league id from your espn url
league_id = 1234567890
LEAGUE_URL = "http://games.espn.com/flb/leaguerosters?leagueId={}"
html = requests.get(LEAGUE_URL.format(league_id)).text

# parse the page to return the rosters table
soup = BeautifulSoup(html)
rosters = soup.find_all("table", {'class': 'playerTableTable'})

# loop through the rosters table and get all of the associated values
players = []
for roster in rosters:
    team_name = roster.find("a").text
    players_html = roster.find_all("td", {'class': 'playertablePlayerName'})
    for player in players_html:

        # parse player info, remove asterisks for injured players.
        player_name = player.text.split(",")[0]
        player_name = player_name.replace("*", "")

        # add to output list
        players.append([player_name, team_name])

# write out to a csv
with open("rosters.csv", "w", newline='') as out_file:
    writer = csv.writer(out_file)
    writer.writerow(("player", "team"))
    writer.writerows(players)
```

### Projections

Player projections are common source of scouting information for our league. Since we do not use the standard scoring rules, the projections from ESPN are mostly worthless to us (not that they're particularly valuable otherwise). For my own purposes, I like the [Depth Charts projection system](https://www.fangraphs.com/projections.aspx?pos=all&stats=bat&type=fangraphsdc) that they use, which is a combination of two other common projection systems (ZiPS and Steamer) weighted by an in-house projection for playing time.

#### Getting Data with cURL

There were two issues I was trying to solve for.

1. **Not enough players** - URL parameters & form fields didn't seem to contain an ability to get more than 50 players at once. Without the ability to scrape all of the players or paginate through them, my automation would only be as useful as the top 50 projected players.
2. **Confusing ASP.net forms** - These use built-in Microsoft libraries that are difficult to parse through the JS to find the form post, even though most of the time it's just a simple post back to the same page. In addition to the form post parameters, these send back somewhere between 50-60kb of base64-encoded page state data, which is a lot of added noise for my purposes.

Using the network tab, I found that the link for 'page size' allowed me to request higher amounts of players than the values in the form dropdown.

1. Navigate to the chrome developer tools network tab.
2. Filter to `method:POST` so you only get the form post and none of the other resource requests.
3. Right click on the post and select `copy` > `copy as cURL (bash)`. 

I ripped that data out into two files, `get_fangraphs.sh` (send the request), and `fangraphs_form_data.txt`. Since the data is over a certain volume with curl, you need to store it in its own file and load it using the `-d` flag.

```sh
curl 'https://www.fangraphs.com/projections.aspx?pos=all&stats=bat&type=fangraphsdc' \
    -H 'Cookie: fgadp=1' \
    -H 'Origin: https://www.fangraphs.com' \
    -H 'Accept-Encoding: gzip, deflate, br' \
    -H 'Accept-Language: en-US,en;q=0.9' \
    -H 'Upgrade-Insecure-Requests: 1' \
    -H 'User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36' \
    -H 'Content-Type: application/x-www-form-urlencoded' \
    -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8' \
    -H 'Cache-Control: max-age=0' \
    -H 'Referer: https://www.fangraphs.com/projections.aspx?pos=all&stats=bat&type=fangraphsdc' \
    -H 'Connection: keep-alive' \
    -H 'DNT: 1' -d @fangraphs_form_data.txt --compressed
```

In the `fangraphs_form_data.txt` file, there was one adjustment to make to get a higher number than 50 entries back: `__EVENTARGUMENT=FireCommand:ProjectionBoard1$dg1$ctl00;PageSize;50` - change this `50` to something like `2500` or so.

Voila! You've now got a page with the HTML table containing all of the projections information there is to want. You can then plug this into beautifulsoup or whatever html parser you want.

### In-Season Actuals

In addition to projections, having in-season results helps improve our judgment and add context to the projections. There are players whom are specifically favored by the projection systems (namely, players with long histories), and players who are treated rather unkindly (small sample sizes).

Getting the ongoing statistics on a per-player basis turned out to be much easier than anything related to the projections. With a little manipulation of URL parameters, you can easily create a page for scraping that contains all of the necessary information in one go.

* [Pitching Stats](https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=al&qual=y&type=c,36,37,38,40,-1,120,121,217,-1,24,41,42,43,44,-1,117,118,119,-1,6,45,124,-1,62,122,13&season=2018&month=0&season1=2018&ind=0&team=0&rost=0&age=0&filter=&players=0&page=1_100000)
* [Batting Stats](https://www.fangraphs.com/leaders.aspx?pos=all&stats=bat&lg=al&qual=y&type=8&season=2018&month=0&season1=2018&ind=0&team=0&rost=0&age=0&filter=&players=0&page=1_10000)

Creating a short script to parse out player rows and add them to another csv for consumption later on turned out to be short work once I figured this bit out. Here's the script I used (uses requests and beautifulsoup, similar to above):

```python
import requests
import csv
from bs4 import BeautifulSoup

PITCHERS_URL = "https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=al&qual=y&type=c,36,37,38,40,-1,120,121,217,-1,24,41,42,43,44,-1,117,118,119,-1,6,45,124,-1,62,122,13&season=2018&month=0&season1=2018&ind=0&team=0&rost=0&age=0&filter=&players=0&page=1_100000"
BATTERS_URL = "https://www.fangraphs.com/leaders.aspx?pos=all&stats=bat&lg=al&qual=y&type=8&season=2018&month=0&season1=2018&ind=0&team=0&rost=0&age=0&filter=&players=0&page=1_10000"
```

Normally, I would use pandas [read_html](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_html.html) function for parsing HTML tables like this (which uses lxml internally, same as BeautifulSoup), but the encoding of this table caused enough havoc that I decided to write the parser myself. If you're in a similar scenario, try that method first!

## Creating a Repeatable Analysis Using Pandas

[Pandas](https://pandas.pydata.org/) is very capable of producing these sorts of information on tabular data in a straightforward, repeatable manner. Our league uses a customized stat list to base our categories on, so we have to derive many of these after getting actuals/projections.

#### Batting Stats

* **HR**: Home Runs
* **K**: Strikeouts
* **RC**: Runs Created (AB \* OBP \* SLG)
* **OBP**: On Base Percentage
* **SLG**: Slugging Percentage

#### Pitching Stats

* **HR**: Home Runs Against
* **K**: Strikeouts
* **ERA**: Earned Run Average
* **QS**: Quality Starts
* **OBA**: On-Base Percentage Against


! There are plenty of different scoring methods used in fantasy. If you want to try this on yours, look at the code repository and add your own stats to the config.yaml file there.

#### Pandas

Bringing this all into pandas is relatively easy, because of its _insanely_ useful `read_csv()` function. Not only does this do your opening/reading for you, it almost always gets the data types correct as well.

```python
import pandas as pd

# read in all outputs
df_rosters = pd.read_csv("rosters.csv")
df_batters = pd.read_csv("batters.csv")
df_batters_projections = pd.read_csv("batters_projections.csv")
df_pitchers = pd.read_csv("pitchers.csv")
df_pitchers_projection = pd.read_csv("pitchers_projections.csv")

```

---
pub_date: 2018-03-15
---
twitter_handle: _zmsy
