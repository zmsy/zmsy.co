title: Automated Fantasy Baseball Strategy using Web Scraping, Pandas, and Bokeh
---
author: Zach Morrissey
---
body:

## Winning Fantasy Baseball in Style

Every year, I've been in the upper tier of the fantasy baseball standings but I've never been able to actually clinch the title. This year, I'm attempting to change all of that by using a number of automated inputs that will alert me to any possible deals on players that I can get and how to do it. Every year our group normally comes up with some very good scouting information, and this year I'm attempting to beat them at their own game by automating it.

#### The Issues With Pre-Season Scouting

The advantages of scouting out fantasy baseball players in our league evaporates about 3 rounds into the draft. Our group traditionally over-indexes on the drafting portion of it, and then adapts a flying-by-the-seat-of-your-pants approach to the rest of the season. I make bad add/drop decisions as the season goes along; unfortunately mid-season fantasy doesn't fit neatly into a set of discrete actions like a draft does. The goal of this project is to fix this particular shortcoming by providing myself with a methodology for doing this throughout the year.

## Getting Data

The data for this exercise comes from a number of places. For a good system, we'll need to retrieve roster data to know who is available, projections to see who is slated to do well, and mid-season player statistics to so who's currently doing well.

### ESPN Roster Data

Our team uses ESPN for our league, which happens to allow access to webpages so long as you take the time to [make the league public](http://games.espn.com/flb/resources/help/content?name=create-league-standard). Getting roster data is fairly straightforward; all you need to do is scrape the rosters page for that league ID. This is an example of that:

```python
import requests
from bs4 import BeautifulSoup

# rip your league id from your espn url
league_id = 1234567890
requests.get('http://games.espn.com/flb/leaguerosters?leagueId={}'.format(league_id))
```

### Projections

Player projections are common source of scouting information for our league. Since we do not use the standard scoring rules, the projections from ESPN are mostly worthless to us (not that they're of much value otherwise). For my own purposes, I like the [Depth Charts projection system](https://www.fangraphs.com/projections.aspx?pos=all&stats=bat&type=fangraphsdc) that they use, which is a combination of two other common projection systems (ZiPS and Steamer) weighted by an in-house projection for playing time.

For the implementation portion of this piece, I created a python script that downloads the information from Fangraphs and saves it as a csv file. For projections, this turned out to be a little trickier than I had intended it to be, since it was hooked up as a javascript postback using ASP.net forms instead of a simpler get/post request directly to a URL that I could see and steal.

After gleaning a bit of help from [this 2011 web scraping post I found helpful](https://scraperwiki.com/2011/11/how-to-get-along-with-an-asp-webpage/):
* This page uses the javascript `__doPostBack` function to invoke a post to the form that's on this page.
* Python's `requests` library _should_ be able to send the same parameters to download the file.
* Ripping the `__EVENTTARGET` and `__EVENTVALUE` values should be enough to get me going.

That effort to trace down those pieces of info produced this, which works for the CSV download:

```python
for date in date_range:
    scrape_data(date)
```

### In-Season Actuals

In addition to projections, having in-season results helps improve our judgment and add context to the projections. There are players whom are specifically favored by the projection systems (namely, players with long histories), and players who are treated rather unkindly (small sample sizes).

Getting the ongoing statistics on a per-player basis turned out to be much easier than anything related to the projections. With a little manipulation of URL parameters, you can easily create a page for scraping that contains all of the necessary information in one go.

* [Pitching Stats](https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=al&qual=20&type=c,36,37,38,40,-1,120,121,217,-1,24,41,42,43,44,-1,117,118,119,-1,6,45,124,-1,62,122,13&season=2017&month=0&season1=2017&ind=0&team=0&rost=0&age=0&filter=&players=0&page=1_100000)
* [Batting Stats](https://www.fangraphs.com/leaders.aspx?pos=all&stats=bat&lg=al&qual=0&type=8&season=2017&month=0&season1=2017&ind=0&team=0&rost=0&age=0&filter=&players=0&page=1_10000)

Creating a short script to parse out player rows and add them to another csv for consumption later on turned out to be short work once I figured this bit out.

## Creating a Repeatable Analysis Using Pandas

[Pandas](https://pandas.pydata.org/) is very capable of producing these sorts of information on tabular data in a straightforward, repeatable manner. 
---
pub_date: 2018-03-11
---
twitter_handle: _zmsy
