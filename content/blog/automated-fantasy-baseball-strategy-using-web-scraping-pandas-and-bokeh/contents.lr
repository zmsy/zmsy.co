title: Automated Fantasy Baseball Strategy using Web Scraping, Pandas, and Bokeh
---
author: Zach Morrissey
---
body:

## Winning Fantasy Baseball in Style

Every year I've missed the title in fantasy baseball. This year, I'm attempting to change all of that by using a number of automated inputs that will alert me to any possible deals on players that I can get and how to do it. Every year our group normally comes up with some very good scouting information, and this year I'm attempting to beat them all out by automating it.

### The Issues With Pre-Season Scouting

The advantages of scouting out fantasy baseball players in our league evaporates about 3 rounds into the draft. Our group traditionally over-indexes on the drafting portion of it, and then adapts a flying-by-the-seat-of-your-pants approach to the rest of the season. I tend to make bad add/drop decisions as the season goes along. The goal of this project is to fix this particular shortcoming by providing myself with a methodology for doing this throughout the year.

## Getting Data

The data for this exercise comes from a number of places. For a good system, we'll need to retrieve roster data to know who is available, projections to see who is slated to do well, and mid-season player statistics to so who's currently doing well.

### ESPN Roster Data

Our team uses ESPN for our league, which happens to allow access to webpages so long as you take the time to [make the league public](http://games.espn.com/flb/resources/help/content?name=create-league-standard). Getting roster data is fairly straightforward; all you need to do is scrape the rosters page for that league ID. This is an example of that:

```python
import requests
from bs4 import BeautifulSoup

# rip your league id from your espn url
league_id = 1234567890
requests.get('http://games.espn.com/flb/leaguerosters?leagueId={}'.format(league_id))
```

### Projections

Player projections are common source of scouting information for our league. Since we do not use the standard scoring rules, the projections from ESPN are mostly worthless to us (not that they're of much value otherwise). For my own purposes, I like the [Depth Charts projection system](https://www.fangraphs.com/projections.aspx?pos=all&stats=bat&type=fangraphsdc) that they use, which is a combination of two other common projection systems (ZiPS and Steamer) weighted by an in-house projection for playing time.

For the implementation portion of this piece, I created a python script that downloads the information from Fangraphs and saves it as a csv file. For projections, this turned out to be a little trickier than I had intended it to be, since it was hooked up as a javascript postback using ASP.net forms and I had no experience with any of that.

#### ASP Forms Galore

After gleaning a bit of help from [this 2011 web scraping post I found helpful](https://scraperwiki.com/2011/11/how-to-get-along-with-an-asp-webpage/):
* This page uses the javascript `__doPostBack` function to invoke a post to the form that's on this page.
* Python's `requests` library _should_ be able to send the same parameters to download the file.
* Ripping the `__EVENTTARGET` and `__EVENTVALUE` values should be enough to get me going.

This snazzy bit of insight led me to multiple frustrating dead ends.
* Tried ripping the values out by editing the site's javascript and printing them to the console. This quickly led me deeper into MS's ASP javascript library, so I abandoned it.
* Realized just by looking at the onclick listener that they're not actually sending any parameters, it's just one big ol' post to the same page. 
* The URL parameters didn't seem to make much difference to the data appearing on the page. I had hoped I could just edit these to get what I needed.
* Since I've never really tried to download files in an automatic manner before, it hadn't occurred to me that direct file downloads don't show up in chrome's network tab in the developer tools. I navigated my way to chrome's network internals logs (`chrome://net-internals/#events`) where you can see this stuff happen in real time. Looking through the actual http posts didn't seem to provide much insight into how I could actually download the file, as again there was no discernable form information that made any sense to me, and a few feeble attempts at writing something up weren't working at all.

I firmly believe there was a way to do it that I didn't piece together, but I decided to take a different approach.

#### Finally Getting It Right with Selenium

Enter web automation framework [selenium](https://stackoverflow.com/questions/12812001/how-to-download-a-file-from-a-asp-website-in-python) which was recommended for similar tasks. I've used it before in some minor QA work, but there's a endless trove of stack overflow questions out there that were able to help me out on this one. Here's the Dockerfile I made for it.

```docker
FROM ubuntu:16.04

ENV CODE_DIR /code
WORKDIR ${CODE_DIR}

RUN apt-get update \
    && apt-get install -y wget \
    && unzip \
    && libxi6 \
    && libgconf-2-4 \
    && libnss3 \
    && python3

RUN pip3 install selenium
```

### In-Season Actuals

In addition to projections, having in-season results helps improve our judgment and add context to the projections. There are players whom are specifically favored by the projection systems (namely, players with long histories), and players who are treated rather unkindly (small sample sizes).

Getting the ongoing statistics on a per-player basis turned out to be much easier than anything related to the projections. With a little manipulation of URL parameters, you can easily create a page for scraping that contains all of the necessary information in one go.

* [Pitching Stats](https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=al&qual=20&type=c,36,37,38,40,-1,120,121,217,-1,24,41,42,43,44,-1,117,118,119,-1,6,45,124,-1,62,122,13&season=2017&month=0&season1=2017&ind=0&team=0&rost=0&age=0&filter=&players=0&page=1_100000)
* [Batting Stats](https://www.fangraphs.com/leaders.aspx?pos=all&stats=bat&lg=al&qual=0&type=8&season=2017&month=0&season1=2017&ind=0&team=0&rost=0&age=0&filter=&players=0&page=1_10000)

Creating a short script to parse out player rows and add them to another csv for consumption later on turned out to be short work once I figured this bit out.

## Creating a Repeatable Analysis Using Pandas

[Pandas](https://pandas.pydata.org/) is very capable of producing these sorts of information on tabular data in a straightforward, repeatable manner. 
---
pub_date: 2018-03-11
---
twitter_handle: _zmsy
